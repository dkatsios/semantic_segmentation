{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "voc2012.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/dkatsios/semantic_segmentation/blob/master/voc2012.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "43IKGALxGDr4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from shutil import unpack_archive\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import Image\n",
        "import PIL\n",
        "from keras.optimizers import Adam\n",
        "from time import time\n",
        "from google.colab import files\n",
        "from keras.models import load_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "foYYmKrmKCEq",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Download VOC 2012 dataset"
      ]
    },
    {
      "metadata": {
        "id": "Y-njzkyzDplH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# %mkdir semantic_segmentation\n",
        "# %cd semantic_segmentation/\n",
        "# !wget http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
        "# unpack_archive('VOCtrainval_11-May-2012.tar', './')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IHhrJrEpcBgV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%cd /content/semantic_segmentation/VOCdevkit/VOC2012\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LNq2KWv31kW2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imgs_folder = './JPEGImages/'\n",
        "classes_folder = './SegmentationClass/'\n",
        "train_list_path = './ImageSets/Segmentation/train.txt'\n",
        "val_list_path = './ImageSets/Segmentation/val.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "c32_Y5H9KQOe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Import helpers and Model files"
      ]
    },
    {
      "metadata": {
        "id": "iRS1BasOH9_L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "guNQw-HoICFy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from voc2012_helpers import *\n",
        "from atrusunet import  *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GJYzkWcOKWmm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Set parameters"
      ]
    },
    {
      "metadata": {
        "id": "E_UVWO53JEMZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_shape = 512, 512, 3\n",
        "filters = 64\n",
        "segmentation_classes = 21\n",
        "steps = 5\n",
        "out_resized_levels = 4\n",
        "kernel_sizes = [2, 3, 5]\n",
        "batch_size = 4\n",
        "epochs = 7\n",
        "val_steps = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ikAKnviJJfKg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build generators"
      ]
    },
    {
      "metadata": {
        "id": "htwoddmUJiN4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train_lists, val_lists = get_lists_from_folders(train_list_path, val_list_path, imgs_folder, classes_folder)\n",
        "# train_arrays = get_imgs_classes_arrays(*train_lists, img_shape)\n",
        "# val_arrays = get_imgs_classes_arrays(*val_lists, img_shape)\n",
        "# steps_per_epoch= len(train_lists[0]) // batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y5gW0hS7K-zu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_gen = imgs_generator(*train_arrays, batch_size, out_resized_levels, segmentation_classes)\n",
        "val_gen = imgs_generator(*val_arrays, batch_size, out_resized_levels, segmentation_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-T1pn456JmX9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Build model"
      ]
    },
    {
      "metadata": {
        "id": "kmb58dH0JWJz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "atrous_unet = AtrousUnet(img_shape, filters, segmentation_classes,\n",
        "                         steps, out_resized_levels, kernel_sizes)\n",
        "\n",
        "atrous_unet.build_model()\n",
        "print('number of parameters:', atrous_unet.model.count_params())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SFwX9lz_wRPf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Compile model"
      ]
    },
    {
      "metadata": {
        "id": "z0-6eq9zwUcX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizer = Adam(0.001)\n",
        "\n",
        "losses = ['categorical_crossentropy'] * (out_resized_levels + 1)  # mse\n",
        "atrous_unet.model.compile(optimizer=optimizer, loss=losses, metrics=['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mt0sIeY2TkTj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Train model"
      ]
    },
    {
      "metadata": {
        "id": "IOqy9baDTpDC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class_weight = {key:1/segmentation_classes if key < segmentation_classes\n",
        "                else 0 for key in range(segmentation_classes + 1)}\n",
        "\n",
        "history = atrous_unet.model.fit_generator(train_gen,\n",
        "                                          steps_per_epoch=steps_per_epoch, epochs=epochs,\n",
        "                                          verbose=1, validation_data=val_gen, validation_steps=val_steps,\n",
        "                                          class_weight=class_weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b0psim7oIYXn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "atrous_unet.model.save('atrous_unet_model_weights_7_epochs.h5')\n",
        "files.download('atrous_unet_model_weights_7_epochs.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ptoytQ-rKWlo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# atrous_unet = AtrousUnet(img_shape, filters, segmentation_classes,\n",
        "#                          steps, out_resized_levels, kernel_sizes)\n",
        "# atrous_unet.build_model()\n",
        "model = load_model('atrous_unet_model_weights_10_epochs.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8ace_nSJ3EoJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_cmap_dict(reversed=False):\n",
        "  def color_map(N=256, normalized=False):\n",
        "    \n",
        "    def bitget(byteval, idx):\n",
        "        return ((byteval & (1 << idx)) != 0)\n",
        "\n",
        "    dtype = 'float32' if normalized else 'uint8'\n",
        "    cmap = np.zeros((N, 3), dtype=dtype)\n",
        "    \n",
        "    for i in range(N):\n",
        "        r = g = b = 0\n",
        "        c = i\n",
        "        for j in range(8):\n",
        "            r = r | (bitget(c, 0) << 7-j)\n",
        "            g = g | (bitget(c, 1) << 7-j)\n",
        "            b = b | (bitget(c, 2) << 7-j)\n",
        "            c = c >> 3\n",
        "        cmap[i] = np.array([r, g, b])\n",
        "    cmap = cmap/255 if normalized else cmap\n",
        "    return cmap\n",
        "  \n",
        "  cmap = color_map()\n",
        "  cmap_dict = dict()\n",
        "  for i in range(cmap.shape[0]):\n",
        "    if reversed:\n",
        "      cmap_dict[i] = cmap[i]\n",
        "    else:\n",
        "      cmap_dict[tuple(cmap[i].astype(np.int64))] = i\n",
        "  return cmap_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bDOdlABg2owk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_images_from_predictions(preds):\n",
        "  cmap_dict = get_cmap_dict(reversed=True)\n",
        "  preds = np.argmax(preds, axis=-1)\n",
        "  imgs = np.zeros((*preds.shape, 3))\n",
        "  for i, pred in enumerate(preds):\n",
        "    for j in range(pred.shape[0]):\n",
        "      for k in range(pred.shape[1]):\n",
        "        imgs[i, j, k, :] = cmap_dict[pred[j, k]]\n",
        "  \n",
        "  return imgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bdCd8P5U2B3O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "imgs, labels = val_gen.__next__()\n",
        "predictions = atrous_unet.model.predict_on_batch(imgs)\n",
        "pred_labels = predictions[-1]\n",
        "pred_labels = get_images_from_predictions(pred_labels)\n",
        "\n",
        "real_labels = labels[-1]\n",
        "real_labels = get_images_from_predictions(real_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RTFpByDLHiWu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for img, real_label, pred_label in zip(imgs, real_labels, pred_labels):\n",
        "  image = np.concatenate((img, real_label, pred_label), axis=1).astype(np.uint8)\n",
        "  print(np.max(image))\n",
        "#   image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  plt.imshow(image)\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cqMF3CLlJrIO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}