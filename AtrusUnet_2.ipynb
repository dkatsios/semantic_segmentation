{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AtrusUnet_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/dkatsios/semantic_segmentation/blob/master/AtrusUnet_2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "L_mACA3lyT9V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # https://pypi.python.org/pypi/pydot\n",
        "# !pip install pydot\n",
        "# !pip install graphviz\n",
        "# !apt-get install graphviz\n",
        "# import pydot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GaC6vrkTqojX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, Input, Concatenate, Deconv2D, Lambda, Flatten,\\\n",
        "ZeroPadding2D, SeparableConv2D, BatchNormalization, Dropout, MaxPooling2D, Dense\n",
        "from keras.regularizers import l1, l2\n",
        "from keras.models import Model\n",
        "\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XP_C0trfq4qH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AtrousUnet:\n",
        "  def __init__(self, img_shape, filters, out_channels,\n",
        "               steps, out_resized_levels, kernel_sizes=None, dilation_rates=None, use_depthwise=False,\n",
        "               use_max_pooling=True, use_regularizers=True, pre_resized=False, classify=False, dropout_rate=0.4):\n",
        "    self.img_shape = img_shape\n",
        "    self.filters = filters\n",
        "    self.out_channels = out_channels\n",
        "    self.steps = steps\n",
        "    self.out_resized_levels = out_resized_levels\n",
        "    self.dropout_rate = dropout_rate\n",
        "    self.use_max_pooling = use_max_pooling\n",
        "    self.use_regularizers = use_regularizers\n",
        "    self.pre_resized = pre_resized\n",
        "    self.classify = classify\n",
        "    self.kernel_sizes = kernel_sizes if kernel_sizes is not None else [2, 3, 5, 7]\n",
        "    self.dilation_rates = dilation_rates if dilation_rates is not None else [1, 2, 3]\n",
        "    self.kern_reg, self.act_reg = (l2(), l1()) if self.use_regularizers else (None, None)\n",
        "    self.conv = SeparableConv2D if use_depthwise else Conv2D\n",
        "    self.deconv = Deconv2D  # SeparableConvolution2D if use_depthwise else Deconv2D \n",
        "    \n",
        "    assert 2 ** self.steps <= np.min(img_shape[:2]) and \\\n",
        "    self.out_resized_levels <= self.steps\n",
        "    \n",
        "  def resize_img(self, input_tensor):\n",
        "    return tf.image.resize_images(input_tensor[0],\n",
        "                                  input_tensor[1].shape[1:-1])\n",
        "  \n",
        "  def check_shape(self, x):\n",
        "    x_shape = K.int_shape(x)[1:-1]\n",
        "    if x_shape == self.current_shape:\n",
        "      return x\n",
        "    \n",
        "    dr = self.current_shape[0] - x_shape[0]\n",
        "    if dr == 0:\n",
        "      r_pad = 0, 0\n",
        "    elif dr % 2 == 0:\n",
        "      r_pad = dr // 2, dr // 2\n",
        "    else:\n",
        "      r_pad = dr // 2, dr // 2 + 1\n",
        "    \n",
        "    dc = self.current_shape[1] - x_shape[1]\n",
        "    if dc == 0:\n",
        "      c_pad = 0, 0\n",
        "    elif dc % 2 == 0:\n",
        "      c_pad = dc // 2, dc // 2\n",
        "    else:\n",
        "      c_pad = dc // 2, dc // 2 + 1\n",
        "      \n",
        "    assert np.abs(np.array([r_pad, c_pad])).all() <= 1\n",
        "    if dr < 0 or dc < 0:\n",
        "      r = -r_pad[0], x_shape[0] + r_pad[1]\n",
        "      c = -c_pad[0], x_shape[1] + c_pad[1]\n",
        "      x = Lambda(lambda x: x[:,r[0]:r[1],c[0]:c[1],:], name='sh_lambda_%d' % x_shape[0])(x)\n",
        "    else:\n",
        "      x = ZeroPadding2D((r_pad, c_pad))(x)\n",
        "    return x\n",
        "  \n",
        "  def down_sampling_block(self, input_img, input_tensor, ind):\n",
        "    \"\"\"\n",
        "    The downsampling block takes as input the original image (input_img)\n",
        "    and the output of the previous downsampling block (input_tensor).\n",
        "    Steps:\n",
        "      - downsampling (kernel 2x2, strides 2) of 'input_tensor' to half its shape to 'down_sampled'\n",
        "      - for each kernel size:\n",
        "        - convolution with this kernel size, strides 1 and dilation 2\n",
        "        - downsampling (convolution) with kernel 2x2 and strides 2\n",
        "      - concatenation of the last one with 'down_sampled' to 'down_sampled'\n",
        "      - resize of input_img to the same size as 'down_sampled' to 'resized_img'\n",
        "      - convolution of 'down_sampled'  with kernel 1x1\n",
        "      - concatenation of 'down_sampled' with 'resized_img' to total channels 2*filters\n",
        "      - batch normalization.\n",
        "    \"\"\"\n",
        "    ###############\n",
        "    kern_reg, act_reg = self.kern_reg, self.act_reg\n",
        "    dilated = []\n",
        "    for k in self.kernel_sizes:\n",
        "      for d in self.dilation_rates:\n",
        "        name = 'ds_%d_conv_kern_%d_dil_%d' % (ind, k, d)\n",
        "        x = self.conv(self.filters // 2, (k, k), strides=(1, 1), activation='relu',\n",
        "#                       depthwise_regularizer=kern_reg, pointwise_regularizer=kern_reg, activity_regularizer=act_reg,\n",
        "                      padding='same', dilation_rate=(d, d),\n",
        "                      name=name)(input_tensor)\n",
        "        dilated.append(x)\n",
        "    ###############        \n",
        "    concatenated = Concatenate(name='ds_%d_conc' % ind)([*dilated])\n",
        "    if self.use_max_pooling:\n",
        "      shortened = Conv2D(2 * self.filters, (1, 1), activation='relu',\n",
        "                         kernel_regularizer=kern_reg, activity_regularizer=act_reg,\n",
        "                         padding='same', name='ds_%d_conv_short' % ind)(concatenated)\n",
        "      down_sampled = MaxPooling2D(name='ds_%d_maxpool' % ind)(shortened)\n",
        "    else:\n",
        "      down_sampled = self.conv(2 * self.filters, (3, 3), strides=(2, 2), activation='relu',\n",
        "                               depthwise_regularizer=kern_reg, pointwise_regularizer=kern_reg,\n",
        "                               activity_regularizer=act_reg,\n",
        "                               padding='same',\n",
        "                               name='ds_%d_conv_downsamp' % ind)(concatenated)\n",
        "    \n",
        "#     down_sampled = BatchNormalization()(down_sampled)\n",
        "    down_sampled = Dropout(self.dropout_rate, name='ds_%d_dropout' % ind)(down_sampled)\n",
        "    ###############\n",
        "    if self.pre_resized:\n",
        "      self.current_shape = K.int_shape(down_sampled)[1:-1]\n",
        "      resized_img = input_img\n",
        "      resized_img = self.check_shape(resized_img)\n",
        "    else:\n",
        "      resized_img = Lambda(self.resize_img, name='ds_%d_lambda' % ind)([input_img, down_sampled])\n",
        "    merged = Concatenate(name='ds_%d_conc_merged' % ind)([down_sampled, resized_img])\n",
        "    ###############\n",
        "    return merged\n",
        "  \n",
        "  def up_sampling_block(self, down, same, ind):\n",
        "    \"\"\"\n",
        "    The upsampling block takes as input the output of the previous upsampling block (down)\n",
        "    and the output of the downsampling block of the same level (same).\n",
        "    Steps:\n",
        "      - upsampling (deconvolution) of 'down' to the shape of 'same'\n",
        "      - concatenation of the previous one with the 'same' to the 'concatenated'\n",
        "      - convolution of the 'concatenated' to same shape and standard filters\n",
        "      - batch normalization of previous\n",
        "      - optionally convolves to 1x1 filters and output channels for intermediate loss.\n",
        "    \"\"\"\n",
        "    self.current_shape = K.int_shape(same)[1:-1]\n",
        "    kern_reg, act_reg = self.kern_reg, self.act_reg\n",
        "    upsampled = []\n",
        "    out_name = 'prediction' if ind == (self.steps+1) else 'resized_%d' % (self.steps + 1 - ind)\n",
        "    \n",
        "    for k in self.kernel_sizes:\n",
        "      if k == 1 and len(self.kernel_sizes) != 1:\n",
        "        continue\n",
        "      \n",
        "      x = self.deconv(self.filters // 2, (k, k), activation='relu',\n",
        "#                       kernel_regularizer=kern_reg, activity_regularizer=act_reg,\n",
        "                      strides=(2, 2), padding='same', name='us_%d_deconv_kern_%d' % (ind, k))(down)\n",
        "      x = self.check_shape(x)\n",
        "      upsampled.append(x)\n",
        "    \n",
        "    concatenated = Concatenate(name='us_%d_conc' % ind)([*upsampled, same])\n",
        "    up_sampled = Conv2D(2 * self.filters, (1, 1), activation='relu',\n",
        "                        kernel_regularizer=kern_reg, activity_regularizer=act_reg,\n",
        "                        padding='same', name='us_%d_conv' % ind)(concatenated)\n",
        "    \n",
        "#     up_sampled = BatchNormalization()(up_sampled)\n",
        "    \n",
        "    out_sampled = Conv2D(self.out_channels + 1, (1, 1), activation='softmax',\n",
        "                         padding='same', name=out_name)(up_sampled)\n",
        "    \n",
        "    up_sampled = Dropout(self.dropout_rate, name='us_%d_dropout' % ind)(up_sampled)\n",
        "    \n",
        "    return [up_sampled, out_sampled]\n",
        "  \n",
        "#   def build_toy_model(self):\n",
        "#     input_img = Input(self.img_shape)\n",
        "#     x = Conv2D(self.filters, (3, 3), activation='relu', padding='same')(input_img)\n",
        "#     x = Conv2D(self.filters, (5, 5), activation='relu', padding='same')(x)\n",
        "#     x = Conv2D(self.filters, (7, 7), activation='relu', padding='same')(x)\n",
        "#     out = Conv2D(self.out_channels + 1, (1, 1), activation='softmax', padding='same', name='prediction')(x)\n",
        "#     self.model = Model(input_img, out)\n",
        "\n",
        "  def get_encoding(self, input, encoding_size):\n",
        "    x = self.conv(self.filters // 2, (3, 3), strides=(2, 2),\n",
        "                  padding='same', name='encoding_%d_conv' % encoding_size,activation='relu')(input)\n",
        "    x = Flatten(x, name='encoding_%d_flatten' % encoding_size)\n",
        "    name = 'labels' if encoding_size == (self.out_channels + 1) else 'encoding_%d' % encoding_size\n",
        "    encoding = Dense(encoding_size, activation='sigmoid', name=name)(x)\n",
        "    return encoding\n",
        "  \n",
        "  def build_model(self):\n",
        "    \"\"\"\n",
        "    The model has the downsample stage and the upsample stage.\n",
        "    The downsample stage has the original image and n steps of the downsampling block.\n",
        "    The upsample stage has n steps of the upsampling block and the original image.\n",
        "    The loss is computed over the last result (original image shape) and m resized results (up_sampled).\n",
        "    \"\"\"\n",
        "    input_img = [Input(self.img_shape, name='or_image')]\n",
        "\n",
        "    # downsampling stage\n",
        "    down_sampled = [input_img[-1]]\n",
        "    for i in range(self.steps):\n",
        "      if self.pre_resized:\n",
        "        resized_shape = self.img_shape[0] // (2 ** (i+1)), self.img_shape[1] // (2 ** (i+1)), self.img_shape[2]\n",
        "        input_img.append(Input(resized_shape, name='resized_image_%d' % (i+1)))\n",
        "      \n",
        "      down_sampled.append(self.down_sampling_block(input_img[-1], down_sampled[i], i))\n",
        "    \n",
        "    # upsampling stage\n",
        "    up_results = down_sampled[-1],\n",
        "    for i in range(2, self.steps+2):\n",
        "      up_results = self.up_sampling_block(up_results[0],\n",
        "                                          down_sampled[-i], i)\n",
        "      up_sampled.append(up_results[1])\n",
        "    \n",
        "    up_sampled = up_sampled[-(self.out_resized_levels + 1):]\n",
        "    \n",
        "    if self.classify:\n",
        "      labels = self.get_encoding(down_sampled[-1], self.out_channels + 1)\n",
        "      up_sampled.append(labels)\n",
        "      \n",
        "    if len(up_sampled) == 1:\n",
        "      up_sampled = up_sampled[0]\n",
        "      \n",
        "    # model\n",
        "    model = Model(input_img, up_sampled)\n",
        "    assert self.img_shape[:-1] == model.layers[-1].output_shape[1:-1]\n",
        "    \n",
        "    self.model = model\n",
        "#     self.build_toy_model()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hckMfqk5yPEW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  img_shape = 256, 256, 3\n",
        "  filters = 64\n",
        "  out_channels = 20\n",
        "  steps = 5\n",
        "  out_resized_levels = 2\n",
        "  kernel_sizes = [2, 3, 5]\n",
        "  atrous_unet = AtrousUnet(img_shape, filters, out_channels,\n",
        "                           steps, out_resized_levels, kernel_sizes)\n",
        "  atrous_unet.build_model()\n",
        "  losses = ['mse'] * (out_resized_levels + 1)  # binary_crossentropy\n",
        "  atrous_unet.model.compile(optimizer='Adam', loss=losses, metrics=['accuracy'])\n",
        "\n",
        "  print('number of parameters:', atrous_unet.model.count_params())\n",
        "  # print(atrous_unet.model.summary())\n",
        "  # SVG(model_to_dot(atrous_unet.model, show_shapes=True,\n",
        "  #                  show_layer_names=False).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}