{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AtrusUnet_2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/dkatsios/semantic_segmentation/blob/master/AtrusUnet_2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "L_mACA3lyT9V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # https://pypi.python.org/pypi/pydot\n",
        "# !pip install pydot\n",
        "# !pip install graphviz\n",
        "# !apt-get install graphviz\n",
        "# import pydot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GaC6vrkTqojX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, Input, Concatenate, Deconv2D, Lambda, ZeroPadding2D, SeparableConv2D, BatchNormalization, MaxPooling2D, Dropout\n",
        "from keras.regularizers import l1, l2, activity_l1, activity_l2, activity_l1l2\n",
        "from keras.models import Model\n",
        "\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "# from IPython.display import SVG\n",
        "# from keras.utils.vis_utils import model_to_dot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XP_C0trfq4qH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AtrousUnet:\n",
        "  def __init__(self, img_shape, filters, out_channels,\n",
        "               steps, out_levels, kernel_sizes=None, dilation_rates=None, use_depthwise=False, dropout_rate=0.5):\n",
        "    self.img_shape = img_shape\n",
        "    self.filters = filters\n",
        "    self.out_channels = out_channels\n",
        "    self.steps = steps\n",
        "    self.out_levels = out_levels\n",
        "    self.dropout_rate = dropout_rate\n",
        "    self.kernel_sizes = kernel_sizes if kernel_sizes is not None else [2, 3, 5, 7]\n",
        "    self.dilation_rates = dilation_rates if dilation_rates is not None else [1, 2, 3]\n",
        "    self.conv = SeparableConv2D if use_depthwise else Conv2D\n",
        "    self.deconv = Deconv2D  # SeparableConvolution2D if use_depthwise else Deconv2D \n",
        "    \n",
        "    assert 2 ** self.steps <= np.min(img_shape[:2]) and \\\n",
        "    self.out_levels <= self.steps\n",
        "    \n",
        "  def resize_img(self, input_tensor):\n",
        "    return tf.image.resize_images(input_tensor[0],\n",
        "                                  input_tensor[1].shape[1:-1])\n",
        "  \n",
        "  def check_shape(self, x):\n",
        "    x_shape = K.int_shape(x)[1:-1]\n",
        "    if x_shape == self.current_shape:\n",
        "      return x\n",
        "    \n",
        "    dr = self.current_shape[0] - x_shape[0]\n",
        "    if dr == 0:\n",
        "      r_pad = 0, 0\n",
        "    elif dr % 2 == 0:\n",
        "      r_pad = dr // 2, dr // 2\n",
        "    else:\n",
        "      r_pad = dr // 2, dr // 2 + 1\n",
        "    \n",
        "    dc = self.current_shape[1] - x_shape[1]\n",
        "    if dc == 0:\n",
        "      c_pad = 0, 0\n",
        "    elif dc % 2 == 0:\n",
        "      c_pad = dc // 2, dc // 2\n",
        "    else:\n",
        "      c_pad = dc // 2, dc // 2 + 1\n",
        "      \n",
        "    assert np.abs(np.array([r_pad, c_pad])).all() <= 1\n",
        "    if dr < 0 or dc < 0:\n",
        "      r = -r_pad[0], x_shape[0] + r_pad[1]\n",
        "      c = -c_pad[0], x_shape[1] + c_pad[1]\n",
        "      x = Lambda(lambda x: x[:,r[0]:r[1],c[0]:c[1],:])(x)\n",
        "    else:\n",
        "      x = ZeroPadding2D((r_pad, c_pad))(x)\n",
        "    return x\n",
        "  \n",
        "  def down_sampling_block(self, input_img, input_tensor, ind):\n",
        "    \"\"\"\n",
        "    The downsampling block takes as input the original image (input_img)\n",
        "    and the output of the previous downsampling block (input_tensor).\n",
        "    Steps:\n",
        "      - downsampling (kernel 2x2, strides 2) of 'input_tensor' to half its shape to 'down_sampled'\n",
        "      - for each kernel size:\n",
        "        - convolution with this kernel size, strides 1 and dilation 2\n",
        "        - downsampling (convolution) with kernel 2x2 and strides 2\n",
        "      - concatenation of the last one with 'down_sampled' to 'down_sampled'\n",
        "      - resize of input_img to the same size as 'down_sampled' to 'resized_img'\n",
        "      - convolution of 'down_sampled'  with kernel 1x1\n",
        "      - concatenation of 'down_sampled' with 'resized_img' to total channels 2*filters\n",
        "      - batch normalization.\n",
        "    \"\"\"\n",
        "    ###############\n",
        "    dilated = []\n",
        "    for k in self.kernel_sizes:\n",
        "      for dr in self.dilation_rates:\n",
        "        x = self.conv(self.filters // 2, (k, k), strides=(1, 1), activation='relu',\n",
        "                      depthwise_regularizer=l2(), pointwise_regularizer=l2(), activity_regularizer=activity_l1l2(),\n",
        "                      padding='same', dilation_rate=(dr, dr))(input_tensor)\n",
        "        dilated.append(x)\n",
        "    ###############        \n",
        "    concatenated = Concatenate()([*dilated])\n",
        "    down_sampled = self.conv(2 * self.filters - input_img.get_shape().as_list()[-1],\n",
        "                             (3, 3), strides=(2, 2), activation='relu',\n",
        "                             depthwise_regularizer=l2(), pointwise_regularizer=l2(),\n",
        "                             activity_regularizer=activity_l1l2(),\n",
        "                             padding='same')(concatenated)\n",
        "    down_sampled = BatchNormalization()(down_sampled)\n",
        "    down_sampled = Dropout(self.dropout_rate)(down_sampled)\n",
        "    ###############\n",
        "    resized_img = Lambda(self.resize_img)([input_img, down_sampled])\n",
        "    merged = Concatenate()([down_sampled, resized_img])\n",
        "    ###############\n",
        "\n",
        "    return merged\n",
        "  \n",
        "  def up_sampling_block(self, down, same, ind=None):\n",
        "    \"\"\"\n",
        "    The upsampling block takes as input the output of the previous upsampling block (down)\n",
        "    and the output of the downsampling block of the same level (same).\n",
        "    Steps:\n",
        "      - upsampling (deconvolution) of 'down' to the shape of 'same'\n",
        "      - concatenation of the previous one with the 'same' to the 'concatenated'\n",
        "      - convolution of the 'concatenated' to same shape and standard filters\n",
        "      - batch normalization of previous\n",
        "      - optionally convolves to 1x1 filters and output channels for intermediate loss.\n",
        "    \"\"\"\n",
        "    self.current_shape = K.int_shape(same)[1:-1]\n",
        "    upsampled = []\n",
        "    \n",
        "    for k in self.kernel_sizes:\n",
        "      x = self.deconv(self.filters // 2, (k, k), activation='relu',\n",
        "                      depthwise_regularizer=l2(), pointwise_regularizer=l2(),\n",
        "                      activity_regularizer=activity_l1l2(),\n",
        "                      strides=(2, 2), padding='same')(down)\n",
        "      x = self.check_shape(x)\n",
        "      upsampled.append(x)\n",
        "    \n",
        "    concatenated = Concatenate()([*upsampled, same])\n",
        "    up_sampled = self.conv(2 * self.filters, (1, 1), activation='relu',\n",
        "                           depthwise_regularizer=l2(), pointwise_regularizer=l2(),\n",
        "                           activity_regularizer=activity_l1l2(),\n",
        "                           padding='same')(concatenated)\n",
        "    \n",
        "    up_sampled = BatchNormalization()(up_sampled)\n",
        "    \n",
        "    out_sampled = self.conv(self.out_channels+1, (1, 1), activation='softmax',\n",
        "                            depthwise_regularizer=l2(), pointwise_regularizer=l2(),\n",
        "                            activity_regularizer=activity_l1l2(),\n",
        "                            padding='same')(up_sampled)\n",
        "    \n",
        "    up_sampled = Dropout(self.dropout_rate)(up_sampled)\n",
        "    \n",
        "    return [up_sampled, out_sampled]\n",
        "  \n",
        "  def build_model(self):\n",
        "    \"\"\"\n",
        "    The model has the downsample phase and the upsample phase.\n",
        "    The downsample phase has the original image and n steps of the outputs of the downsampling block.\n",
        "    The upsample phase has n steps of the outputs of the upsampling block and the original image.\n",
        "    The loss is computed over the last result (original image shape) and m resized results (up_sampled).\n",
        "    \"\"\"\n",
        "    input_img = Input(self.img_shape)\n",
        "    down_sampled = [input_img]\n",
        "\n",
        "    for i in range(self.steps):\n",
        "      down_sampled.append(self.down_sampling_block(input_img,\n",
        "                                                   down_sampled[i], i))\n",
        "\n",
        "    up_sampled = [down_sampled[-1]]\n",
        "    \n",
        "    up_results = down_sampled[-1],\n",
        "    for i in range(2, self.steps+1):\n",
        "      up_results = self.up_sampling_block(up_results[0],\n",
        "                                          down_sampled[-i], self.steps-i)\n",
        "      \n",
        "      up_sampled.append(up_results[1])\n",
        "      \n",
        "    up_results = self.up_sampling_block(up_results[0], input_img)\n",
        "    \n",
        "    up_sampled = up_sampled[-self.out_levels:]\n",
        "    if self.out_levels == 0:\n",
        "      up_sampled = []\n",
        "    \n",
        "    up_results[0] = BatchNormalization()(up_results[0])\n",
        "    out_img = self.conv(self.out_channels+1, (1, 1), activation='softmax',\n",
        "                        name='out_img')(up_results[0])\n",
        "    up_sampled.append(out_img)\n",
        "    model = Model(input_img, up_sampled)\n",
        "    \n",
        "    \n",
        "    assert self.img_shape[:-1] == model.layers[-1].output_shape[1:-1]\n",
        "    \n",
        "    self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hckMfqk5yPEW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  img_shape = 256, 256, 3\n",
        "  filters = 64\n",
        "  out_channels = 20\n",
        "  steps = 5\n",
        "  out_resized_levels = 2\n",
        "  kernel_sizes = [2, 3, 5]\n",
        "  atrous_unet = AtrousUnet(img_shape, filters, out_channels,\n",
        "                           steps, out_resized_levels, kernel_sizes)\n",
        "  atrous_unet.build_model()\n",
        "  losses = ['mse'] * (out_resized_levels + 1)  # binary_crossentropy\n",
        "  atrous_unet.model.compile(optimizer='Adam', loss=losses, metrics=['accuracy'])\n",
        "\n",
        "  print('number of parameters:', atrous_unet.model.count_params())\n",
        "  # print(atrous_unet.model.summary())\n",
        "  # SVG(model_to_dot(atrous_unet.model, show_shapes=True,\n",
        "  #                  show_layer_names=False).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}