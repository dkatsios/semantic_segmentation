{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "voc2012_helpers.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/dkatsios/semantic_segmentation/blob/master/voc2012_helpers.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "pVOeS71rHllw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "from time import time\n",
        "from keras.utils.np_utils import to_categorical\n",
        "import keras.backend as K\n",
        "import keras\n",
        "import pickle\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bmNz5dAVHRUX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_lists_from_folders(train_list_path, val_list_path, imgs_folder, classes_folder):\n",
        "  train_list = []\n",
        "  with open(train_list_path) as f:\n",
        "    for line in f:\n",
        "      line = line.strip()\n",
        "      if len(line) > 1:\n",
        "        train_list.append(line)\n",
        "        \n",
        "  train_imgs_list = [imgs_folder + name + '.jpg' for name in train_list]\n",
        "  train_classes_list = [classes_folder + name + '.png' for name in train_list]\n",
        "  \n",
        "  val_list = []\n",
        "  with open(val_list_path) as f:\n",
        "    for line in f:\n",
        "      line = line.strip()\n",
        "      if len(line) > 1:\n",
        "        val_list.append(line)\n",
        "        \n",
        "  val_imgs_list = [imgs_folder + name + '.jpg' for name in val_list]\n",
        "  val_classes_list = [classes_folder + name + '.png' for name in val_list]\n",
        "  \n",
        "  train_lists = train_imgs_list, train_classes_list\n",
        "  val_lists = val_imgs_list, val_classes_list\n",
        "  \n",
        "  return train_lists, val_lists"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C8e_CiHMyCi5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_labels(classes_dict):\n",
        "  prediction = classes_dict['prediction']\n",
        "  prediction = prediction[:, :, :, 1:-1]\n",
        "  labels = np.clip(np.sum(prediction, axis=(1, 2)), 0, 1)\n",
        "  classes_dict['labels'] = labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oERorojzynZe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def imgs_generator(rgb_imgs, num_classes, batch_size, out_resized_levels,\n",
        "                   segmentation_classes, pre_resized, classify, steps):\n",
        "  while True:\n",
        "    inds = np.random.randint(0, rgb_imgs.shape[0], batch_size)\n",
        "    batch_imgs = rgb_imgs[inds]\n",
        "    if pre_resized:\n",
        "      batch_imgs = get_pre_resized(batch_imgs, steps)\n",
        "    batch_classes = get_resized(num_classes[inds], out_resized_levels, segmentation_classes)[::-1]\n",
        "    if isinstance(batch_classes, list):\n",
        "      classes_dict = {'prediction': batch_classes.pop()}\n",
        "      for i in range(1, out_resized_levels + 1):\n",
        "        classes_dict['resized_%d' % i] = batch_classes.pop()\n",
        "    else:\n",
        "      classes_dict = {'prediction': batch_classes}\n",
        "    if classify:\n",
        "      add_labels(classes_dict)\n",
        "    yield batch_imgs, classes_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QIyq3eTPylIH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_resized(num_classes, out_resized_levels, segmentation_classes):\n",
        "  batch_size = num_classes.shape[0]\n",
        "  or_size = num_classes.shape[1:]\n",
        "  assert len(or_size) == 2, num_classes.shape\n",
        "  if out_resized_levels == 0:\n",
        "    return make_one_hot(num_classes, segmentation_classes)\n",
        "  resized_classes = [make_one_hot(num_classes, segmentation_classes)]\n",
        "  for i in range(out_resized_levels):\n",
        "    size = or_size[0] // (2 ** (i+1)), or_size[1] // (2 ** (i+1))\n",
        "    resized = np.zeros((batch_size, *size))\n",
        "    for j in range(batch_size):\n",
        "      resized[j] = cv2.resize(num_classes[j], size, interpolation=cv2.INTER_NEAREST)\n",
        "    resized = make_one_hot(resized, segmentation_classes)\n",
        "    resized_classes.append(resized)\n",
        "  return resized_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BC6wlB8w2yAT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_cmap_dict(reversed=False):\n",
        "  def color_map(N=256, normalized=False):\n",
        "    \n",
        "    def bitget(byteval, idx):\n",
        "        return ((byteval & (1 << idx)) != 0)\n",
        "\n",
        "    dtype = 'float32' if normalized else 'uint8'\n",
        "    cmap = np.zeros((N, 3), dtype=dtype)\n",
        "    \n",
        "    for i in range(N):\n",
        "        r = g = b = 0\n",
        "        c = i\n",
        "        for j in range(8):\n",
        "            r = r | (bitget(c, 0) << 7-j)\n",
        "            g = g | (bitget(c, 1) << 7-j)\n",
        "            b = b | (bitget(c, 2) << 7-j)\n",
        "            c = c >> 3\n",
        "        cmap[i] = np.array([r, g, b])\n",
        "    cmap = cmap/255 if normalized else cmap\n",
        "    return cmap\n",
        "  \n",
        "  cmap = color_map()\n",
        "  cmap_dict = dict()\n",
        "  for i in range(cmap.shape[0]):\n",
        "    if reversed:\n",
        "      cmap_dict[i] = tuple(cmap[i].astype(np.int64))\n",
        "    else:\n",
        "      cmap_dict[tuple(cmap[i].astype(np.int64))] = i\n",
        "  return cmap_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l6aIM4sTHZ3a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_imgs_classes_arrays(imgs_list, classes_list, img_shape):\n",
        "  assert len(imgs_list) == len(classes_list)\n",
        "\n",
        "  def color_to_nums(num_classes, cmap_dict):\n",
        "    nums = np.zeros(num_classes.shape[:-1], dtype=np.int64)\n",
        "    mul = np.array([1, 10, 100])\n",
        "    factor = np.tile(mul, (*num_classes.shape[:-1], 1))\n",
        "    nums = np.multiply(num_classes, factor)\n",
        "    nums = np.sum(nums, axis=-1)\n",
        "    for key, value in cmap_dict.items():\n",
        "      key = np.asarray(key).astype(np.int64)\n",
        "      key = np.sum(np.multiply(key, mul))\n",
        "      nums[nums == key] = value\n",
        "    return nums\n",
        "  \n",
        "  print('start constructing arrays')\n",
        "  start = time()\n",
        "  cmap_dict = get_cmap_dict()\n",
        "  \n",
        "  img_shape = img_shape\n",
        "  rgb_imgs = np.zeros((len(imgs_list), *img_shape), dtype=np.uint8)\n",
        "  num_classes = np.zeros((len(classes_list), *img_shape[:-1]), dtype=np.uint8)\n",
        "  \n",
        "  for ind in range(len(imgs_list)):\n",
        "    img = cv2.imread(imgs_list[ind])\n",
        "    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    rgb_resized = cv2.resize(rgb_img, img_shape[:-1])\n",
        "    rgb_imgs[ind] = rgb_resized\n",
        "    \n",
        "    cls = cv2.imread(classes_list[ind])\n",
        "    rgb_cls = cv2.cvtColor(cls, cv2.COLOR_BGR2RGB)\n",
        "    cls_resized = cv2.resize(rgb_cls, img_shape[:-1], interpolation=cv2.INTER_NEAREST)\n",
        "    num_class = color_to_nums(cls_resized, cmap_dict)\n",
        "    num_classes[ind] = num_class\n",
        "  print('arrays constructed. time: %d secs' % int(time() - start))\n",
        "  return rgb_imgs, num_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AipTtTrobuGB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_one_hot(batch_labels, segmentation_classes):\n",
        "  batch_labels[batch_labels == 255] = segmentation_classes\n",
        "  categorical_labels = to_categorical(batch_labels, num_classes=segmentation_classes+1)\n",
        "  return categorical_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WoO13HzkBv4Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_class_weight(seg_classes, background_ratio = 1/5):\n",
        "  class_weight = dict()\n",
        "  class_weight[0] = background_ratio / seg_classes\n",
        "  for i in range(1, seg_classes):\n",
        "    class_weight[i] = 1 / seg_classes + (1 - background_ratio) / seg_classes ** 2\n",
        "  class_weight[seg_classes] = 0\n",
        "  return class_weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CaByfLL43JYI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DownloadWeights(keras.callbacks.Callback):\n",
        "  def __init__(self, weights_path):\n",
        "    super(DownloadWeights, self).__init__()\n",
        "    self.weights_path = weights_path\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "#     with open(self.wdir + '/logs.pkl', 'wb') as handle:\n",
        "#       pickle.dump(logs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    files.download(self.weights_path)\n",
        "#     files.download(self.wdir + '/logs.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7zGpTYok3a6e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_images_from_predictions(preds):\n",
        "  cmap_dict = get_cmap_dict(reversed=True)\n",
        "  preds = np.argmax(preds, axis=-1)\n",
        "  imgs = np.zeros((*preds.shape, 3))\n",
        "  for i, pred in enumerate(preds):\n",
        "    for j in range(pred.shape[0]):\n",
        "      for k in range(pred.shape[1]):\n",
        "        imgs[i, j, k, :] = cmap_dict[pred[j, k]]\n",
        "  \n",
        "  return imgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R8NDAu1zfhlI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def jaccard_distance(y_true, y_pred, smooth=100):\n",
        "  # source: https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/losses/jaccard.py\n",
        "  \n",
        "  \"\"\"Jaccard distance for semantic segmentation, also known as the intersection-over-union loss.\n",
        "  This loss is useful when you have unbalanced numbers of pixels within an image\n",
        "  because it gives all classes equal weight. However, it is not the defacto\n",
        "  standard for image segmentation.\n",
        "  For example, assume you are trying to predict if each pixel is cat, dog, or background.\n",
        "  You have 80% background pixels, 10% dog, and 10% cat. If the model predicts 100% background\n",
        "  should it be be 80% right (as with categorical cross entropy) or 30% (with this loss)?\n",
        "  The loss has been modified to have a smooth gradient as it converges on zero.\n",
        "  This has been shifted so it converges on 0 and is smoothed to avoid exploding\n",
        "  or disappearing gradient.\n",
        "  Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n",
        "          = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n",
        "  \"\"\"\n",
        "  intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
        "  sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
        "  jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "  return (1 - jac) * smooth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v9i_3V9NvGjR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss_factor = 10000\n",
        "def dice_coef(y_true, y_pred):\n",
        "  smooth = 1\n",
        "  y_true_f = K.flatten(y_true)\n",
        "  y_pred_f = K.flatten(y_pred)\n",
        "  intersection = K.sum(y_true_f * y_pred_f)\n",
        "  return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "  return -dice_coef(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mZOYfSHrwPeO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_loss_metrics_weights(out_resized_levels, use_dice=True, classify=False,\n",
        "                             only_labels=False, loss_factor=1.):\n",
        "  loss_type = dice_coef_loss if use_dice else jaccard_distance\n",
        "  loss, metrics, loss_weights = dict(), dict(), dict()\n",
        "  \n",
        "  if classify:\n",
        "    loss['labels'] = 'binary_crossentropy'\n",
        "    metrics['labels'] = 'binary_accuracy'\n",
        "    loss_weights['labels'] = loss_factor\n",
        "  \n",
        "    if only_labels:\n",
        "      return loss, metrics, loss_weights\n",
        "    \n",
        "  loss['prediction'] = dice_coef_loss\n",
        "  metrics['prediction'] = [dice_coef, 'categorical_accuracy']\n",
        "  loss_weights['prediction'] = loss_factor\n",
        "  \n",
        "  if out_resized_levels > 0:\n",
        "    for i in range(1, out_resized_levels + 1):\n",
        "      loss['resized_%d' % i] = 'categorical_crossentropy'\n",
        "      metrics['resized_%d' % i] = 'categorical_accuracy'\n",
        "      loss_weights['resized_%d' % i] = loss_factor / (out_resized_levels + 1)\n",
        "    \n",
        "    \n",
        "  return loss, metrics, loss_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "34DVVqLsoZzB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_pre_resized(batch_imgs, steps):\n",
        "  pre_resized_imgs = {'or_image': batch_imgs}\n",
        "  or_size = batch_imgs.shape[1:-1]\n",
        "  for i in range(1, steps+1):\n",
        "    key = 'resized_image_%d' % i\n",
        "    size = or_size[0] // (2 ** i), or_size[1] // (2 ** i)\n",
        "    value = np.zeros((batch_imgs.shape[0], size[0], size[1], batch_imgs.shape[3]))\n",
        "    \n",
        "    for batch in range(batch_imgs.shape[0]):\n",
        "      value[batch] = cv2.resize(batch_imgs[batch], size)\n",
        "      \n",
        "    pre_resized_imgs[key] = value\n",
        "#   for key, value in pre_resized_imgs.items():\n",
        "#     print(key, value.shape)\n",
        "  return pre_resized_imgs"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}