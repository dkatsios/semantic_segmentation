{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "voc2012_helpers.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/dkatsios/semantic_segmentation/blob/master/voc2012_helpers.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "pVOeS71rHllw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.callbacks import Callback\n",
        "import keras.backend as K\n",
        "import keras\n",
        "\n",
        "import pickle\n",
        "import os\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  print('Could not import colab files module')\n",
        "\n",
        "from PIL import Image\n",
        "from scipy.misc import imresize\n",
        "from scipy.ndimage.interpolation import rotate\n",
        "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score\n",
        "import numpy as np\n",
        "import cv2\n",
        "from time import time"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EjliBgD1_MWT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_lists(imgs_folder, classes_folder):\n",
        "  imgs_list, classes_list = [], []\n",
        "  for im_name in os.listdir(imgs_folder):\n",
        "    imgs_list.append(imgs_folder + im_name)\n",
        "    classes_list.append(classes_folder + im_name)\n",
        "  return imgs_list, classes_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bmNz5dAVHRUX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_lists_from_folders(train_list_path, val_list_path, imgs_folder, classes_folder):\n",
        "  train_list = []\n",
        "  with open(train_list_path) as f:\n",
        "    for line in f:\n",
        "      line = line.strip()\n",
        "      if len(line) > 1:\n",
        "        train_list.append(line)\n",
        "        \n",
        "  train_imgs_list = [imgs_folder + name + '.jpg' for name in train_list]\n",
        "  train_classes_list = [classes_folder + name + '.png' for name in train_list]\n",
        "  \n",
        "  val_list = []\n",
        "  with open(val_list_path) as f:\n",
        "    for line in f:\n",
        "      line = line.strip()\n",
        "      if len(line) > 1:\n",
        "        val_list.append(line)\n",
        "        \n",
        "  val_imgs_list = [imgs_folder + name + '.jpg' for name in val_list]\n",
        "  val_classes_list = [classes_folder + name + '.png' for name in val_list]\n",
        "  \n",
        "  train_lists = train_imgs_list, train_classes_list\n",
        "  val_lists = val_imgs_list, val_classes_list\n",
        "  \n",
        "  return train_lists, val_lists"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C8e_CiHMyCi5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def add_labels(classes_dict, single_class):\n",
        "  prediction = classes_dict['prediction']\n",
        "  prediction = prediction[:, :, :, 1:-1]\n",
        "  labels = np.sum(prediction, axis=(1, 2))\n",
        "  if single_class:\n",
        "    inds = np.argmax(labels, axis=-1)\n",
        "    labels = np.zeros(labels.shape)\n",
        "    for i, ind in enumerate(inds):\n",
        "      labels[i, ind] = 1\n",
        "    assert np.array_equal(np.sum(labels, axis=-1), np.ones(labels.shape[0]))\n",
        "  else:\n",
        "    labels = np.clip(labels, 0, 1)\n",
        "    \n",
        "  classes_dict['labels'] = labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ytfRoyeLUayK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def augment_data(batch_imgs, batch_classes, rate=0.5):\n",
        "  \n",
        "  def horizontal_flip(image, segm, rate=0.5):\n",
        "    if np.random.rand() > rate:\n",
        "      return image, segm\n",
        "    image = image[:, ::-1, :]\n",
        "    segm = segm[:, ::-1, :]\n",
        "    return image, segm\n",
        "  \n",
        "  def random_crop(image, segm, crop_size):\n",
        "    h, w, _ = image.shape\n",
        "    top = np.random.randint(0, h - crop_size[0])\n",
        "    left = np.random.randint(0, w - crop_size[1])\n",
        "    bottom = top + crop_size[0]\n",
        "    right = left + crop_size[1]\n",
        "    image = image[top:bottom, left:right, :]\n",
        "    segm = segm[top:bottom, left:right, :]\n",
        "    return image, segm\n",
        "  \n",
        "  def zoom_augmentation(image, segm, zoom_range=(1., 1.3), rate=0.5):\n",
        "    if np.random.rand() > rate:\n",
        "      return image, segm\n",
        "    zoom_range = np.clip(zoom_range, 1., None)\n",
        "    crop_size = image.shape[:-1]\n",
        "    scale_size = np.random.uniform(*zoom_range)\n",
        "    image = imresize(image, scale_size)\n",
        "    segm = imresize(segm, scale_size)\n",
        "    \n",
        "    image, segm = random_crop(image, segm, crop_size)\n",
        "    return image, segm\n",
        "  \n",
        "  \n",
        "  def random_rotation(image, segm, angle_range=(0, 30), rate=0.5):    \n",
        "    if np.random.rand() > rate:\n",
        "      return image, segm\n",
        "    h, w, _ = image.shape\n",
        "    angle = np.random.randint(*angle_range)\n",
        "    \n",
        "    image = rotate(image, angle)\n",
        "    image = resize(image, (h, w))\n",
        "    \n",
        "    segm = rotate(segm, angle)\n",
        "    segm = resize(segm, (h, w))\n",
        "    \n",
        "    return image, segm\n",
        "  \n",
        "  def add_noise(image, segm, sigma=0.1, rate=0.5):\n",
        "    if np.random.rand() > rate:\n",
        "      return image, segm\n",
        "    noise = np.random.norma(0, sigma, image.shape)\n",
        "    image = np.clip(image + noise, -1, 1)\n",
        "    \n",
        "    return image, segm\n",
        "  \n",
        "  for i in range(batch_imgs.shape[0]):\n",
        "    image, segm = batch_imgs[i], batch_classes[i]\n",
        "    image, segm = horizontal_flip(image, segm, rate=rate)\n",
        "    image, segm = zoom_augmentation(image, segm, zoom_range=(1., 1.3), rate=rate)\n",
        "    image, segm = random_rotation(image, segm, angle_range=(0, 30), rate=rate)\n",
        "    image, segm = add_noise(image, segm, sigma=0.1, rate=rate)\n",
        "    \n",
        "    batch_imgs[i], batch_classes[i] = image, segm\n",
        "  \n",
        "  return batch_imgs, batch_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YeJJw76594zP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def isbi_imgs_generator(rgb_imgs, num_classes, batch_size, out_resized_levels, segmentation_classes,\n",
        "                          pre_resized, classify, steps, single_class=False, augment=False):\n",
        "  while True:\n",
        "    inds = np.random.randint(0, rgb_imgs.shape[0], batch_size)\n",
        "    batch_imgs = rgb_imgs[inds].astype(np.float32) / 127.5 - 1\n",
        "    assert np.max(np.abs(batch_imgs)) <= 1\n",
        "    batch_classes = (num_classes[inds] >= (255. / 2)).astype(np.float32)\n",
        "    assert np.max(batch_imgs) <= 1\n",
        "    \n",
        "    if augment:\n",
        "      batch_imgs, batch_classes = augment_data(batch_imgs, batch_classes)\n",
        "      \n",
        "    if pre_resized:\n",
        "      batch_imgs = get_pre_resized(batch_imgs, steps)\n",
        "      \n",
        "    batch_classes = get_resized(batch_classes, out_resized_levels, segmentation_classes)[::-1]\n",
        "      \n",
        "    if isinstance(batch_classes, list):\n",
        "      this_class = batch_classes.pop()\n",
        "      if len(this_class.shape) == 3:\n",
        "        this_class = np.expand_dims(this_class, -1)\n",
        "      classes_dict = {'prediction': this_class}\n",
        "      \n",
        "      for i in range(1, out_resized_levels + 1):\n",
        "        this_class = batch_classes.pop()\n",
        "        if len(this_class.shape) == 3:\n",
        "          this_class = np.expand_dims(this_class, -1)\n",
        "        classes_dict['resized_%d' % i] = this_class\n",
        "    else:\n",
        "      if len(batch_classes.shape) == 3:\n",
        "        batch_classes = np.expand_dims(batch_classes, -1)\n",
        "      classes_dict = {'prediction': batch_classes}\n",
        "      \n",
        "    if classify:\n",
        "      add_labels(classes_dict, single_class)\n",
        "    yield batch_imgs, classes_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oERorojzynZe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def imgs_generator(rgb_imgs, num_classes, batch_size, out_resized_levels, segmentation_classes,\n",
        "                   pre_resized, classify, steps, single_class=False, augment=False):\n",
        "  while True:\n",
        "    inds = np.random.randint(0, rgb_imgs.shape[0], batch_size)\n",
        "    batch_imgs = rgb_imgs[inds].astype(np.float32) / 127.5 - 1\n",
        "    assert np.max(np.abs(batch_imgs)) <= 1\n",
        "    batch_classes = num_classes[inds]\n",
        "    \n",
        "    if augment:\n",
        "      batch_imgs, batch_classes = augment_data(batch_imgs, batch_classes)\n",
        "      \n",
        "    if pre_resized:\n",
        "      batch_imgs = get_pre_resized(batch_imgs, steps)\n",
        "    batch_classes = get_resized(batch_classes, out_resized_levels, segmentation_classes)[::-1]\n",
        "    \n",
        "    if isinstance(batch_classes, list):\n",
        "      classes_dict = {'prediction': batch_classes.pop()}\n",
        "      for i in range(1, out_resized_levels + 1):\n",
        "        classes_dict['resized_%d' % i] = batch_classes.pop()\n",
        "    else:\n",
        "      classes_dict = {'prediction': batch_classes}\n",
        "      \n",
        "    if classify:\n",
        "      add_labels(classes_dict, single_class)\n",
        "    yield batch_imgs, classes_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ppNYaX1J-rgW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_resized(num_classes, out_resized_levels, segmentation_classes):\n",
        "  batch_size = num_classes.shape[0]    \n",
        "  or_size = num_classes.shape[1:]\n",
        "  assert len(or_size) == 2, num_classes.shape\n",
        "  \n",
        "  if segmentation_classes > 1:\n",
        "    num_classes = make_one_hot(num_classes, segmentation_classes)\n",
        "    \n",
        "  if out_resized_levels == 0:\n",
        "    return num_classes[::-1]\n",
        "  resized_classes = [num_classes]\n",
        "  for i in range(out_resized_levels):\n",
        "    size = or_size[0] // (2 ** (i+1)), or_size[1] // (2 ** (i+1))\n",
        "    resized = np.zeros((batch_size, *size))\n",
        "    for j in range(batch_size):\n",
        "      resized[j] = cv2.resize(num_classes[j], size, interpolation=cv2.INTER_NEAREST)\n",
        "    \n",
        "    if segmentation_classes > 1:\n",
        "      resized = make_one_hot(resized, segmentation_classes)\n",
        "      \n",
        "    resized_classes.append(resized)\n",
        "  return resized_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BC6wlB8w2yAT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_cmap_dict(reversed=False):\n",
        "  def color_map(N=256, normalized=False):\n",
        "    \n",
        "    def bitget(byteval, idx):\n",
        "        return ((byteval & (1 << idx)) != 0)\n",
        "\n",
        "    dtype = 'float32' if normalized else 'uint8'\n",
        "    cmap = np.zeros((N, 3), dtype=dtype)\n",
        "    \n",
        "    for i in range(N):\n",
        "        r = g = b = 0\n",
        "        c = i\n",
        "        for j in range(8):\n",
        "            r = r | (bitget(c, 0) << 7-j)\n",
        "            g = g | (bitget(c, 1) << 7-j)\n",
        "            b = b | (bitget(c, 2) << 7-j)\n",
        "            c = c >> 3\n",
        "        cmap[i] = np.array([r, g, b])\n",
        "    cmap = cmap/255 if normalized else cmap\n",
        "    return cmap\n",
        "  \n",
        "  cmap = color_map()\n",
        "  cmap_dict = dict()\n",
        "  for i in range(cmap.shape[0]):\n",
        "    if reversed:\n",
        "      cmap_dict[i] = tuple(cmap[i].astype(np.int64))\n",
        "    else:\n",
        "      cmap_dict[tuple(cmap[i].astype(np.int64))] = i\n",
        "  return cmap_dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q0zU_2oo_WVW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_isbi_imgs_classes_arrays(imgs_list, classes_list, img_shape):\n",
        "  assert len(imgs_list) == len(classes_list)\n",
        "  \n",
        "  rgb_imgs = np.zeros((len(imgs_list), *img_shape), dtype=np.uint8)\n",
        "  num_classes = np.zeros((len(classes_list), *img_shape[:-1]), dtype=np.uint8)\n",
        "  \n",
        "  for ind in range(len(imgs_list)):\n",
        "    img = cv2.imread(imgs_list[ind])\n",
        "    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    rgb_resized = cv2.resize(rgb_img, img_shape[:-1])\n",
        "    rgb_imgs[ind] = rgb_resized\n",
        "    \n",
        "    cls = cv2.imread(classes_list[ind])[:, :, 0]\n",
        "    cls_resized = cv2.resize(cls, img_shape[:-1], interpolation=cv2.INTER_NEAREST)\n",
        "    num_classes[ind] = cls\n",
        "  return rgb_imgs, num_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l6aIM4sTHZ3a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_imgs_classes_arrays(imgs_list, classes_list, img_shape):\n",
        "  assert len(imgs_list) == len(classes_list)\n",
        "\n",
        "  def color_to_nums(num_classes, cmap_dict):\n",
        "    nums = np.zeros(num_classes.shape[:-1], dtype=np.int64)\n",
        "    mul = np.array([1, 10, 100])\n",
        "    factor = np.tile(mul, (*num_classes.shape[:-1], 1))\n",
        "    nums = np.multiply(num_classes, factor)\n",
        "    nums = np.sum(nums, axis=-1)\n",
        "    for key, value in cmap_dict.items():\n",
        "      key = np.asarray(key).astype(np.int64)\n",
        "      key = np.sum(np.multiply(key, mul))\n",
        "      nums[nums == key] = value\n",
        "    return nums\n",
        "  \n",
        "  print('start constructing arrays')\n",
        "  start = time()\n",
        "  cmap_dict = get_cmap_dict()\n",
        "  \n",
        "  img_shape = img_shape\n",
        "  rgb_imgs = np.zeros((len(imgs_list), *img_shape), dtype=np.uint8)\n",
        "  num_classes = np.zeros((len(classes_list), *img_shape[:-1]), dtype=np.uint8)\n",
        "  \n",
        "  for ind in range(len(imgs_list)):\n",
        "    img = cv2.imread(imgs_list[ind])\n",
        "    rgb_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    rgb_resized = cv2.resize(rgb_img, img_shape[:-1])\n",
        "    rgb_imgs[ind] = rgb_resized\n",
        "    \n",
        "    cls = cv2.imread(classes_list[ind])\n",
        "    rgb_cls = cv2.cvtColor(cls, cv2.COLOR_BGR2RGB)\n",
        "    cls_resized = cv2.resize(rgb_cls, img_shape[:-1], interpolation=cv2.INTER_NEAREST)\n",
        "    num_class = color_to_nums(cls_resized, cmap_dict)\n",
        "    num_classes[ind] = num_class\n",
        "  print('arrays constructed. time: %d secs' % int(time() - start))\n",
        "  return rgb_imgs, num_classes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AipTtTrobuGB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def make_one_hot(batch_labels, segmentation_classes):\n",
        "  batch_labels[batch_labels == 255] = segmentation_classes\n",
        "  categorical_labels = to_categorical(batch_labels, num_classes=segmentation_classes+1)\n",
        "  return categorical_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WoO13HzkBv4Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_class_weight(seg_classes, background_ratio = 1/5):\n",
        "  class_weight = dict()\n",
        "  class_weight[0] = background_ratio / seg_classes\n",
        "  for i in range(1, seg_classes):\n",
        "    class_weight[i] = 1 / seg_classes + (1 - background_ratio) / seg_classes ** 2\n",
        "  class_weight[seg_classes] = 0\n",
        "  return class_weight"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CaByfLL43JYI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DownloadWeights(keras.callbacks.Callback):\n",
        "  def __init__(self, weights_path):\n",
        "    super(DownloadWeights, self).__init__()\n",
        "    self.weights_path = weights_path\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "#     with open(self.wdir + '/logs.pkl', 'wb') as handle:\n",
        "#       pickle.dump(logs, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    files.download(self.weights_path)\n",
        "#     files.download(self.wdir + '/logs.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7zGpTYok3a6e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_images_from_predictions(preds):\n",
        "  cmap_dict = get_cmap_dict(reversed=True)\n",
        "  preds = np.argmax(preds, axis=-1)\n",
        "  imgs = np.zeros((*preds.shape, 3))\n",
        "  for i, pred in enumerate(preds):\n",
        "    for j in range(pred.shape[0]):\n",
        "      for k in range(pred.shape[1]):\n",
        "        imgs[i, j, k, :] = cmap_dict[pred[j, k]]\n",
        "  \n",
        "  return imgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R8NDAu1zfhlI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def jaccard_distance(y_true, y_pred, smooth=100):\n",
        "  # source: https://github.com/keras-team/keras-contrib/blob/master/keras_contrib/losses/jaccard.py\n",
        "  \n",
        "  \"\"\"Jaccard distance for semantic segmentation, also known as the intersection-over-union loss.\n",
        "  This loss is useful when you have unbalanced numbers of pixels within an image\n",
        "  because it gives all classes equal weight. However, it is not the defacto\n",
        "  standard for image segmentation.\n",
        "  For example, assume you are trying to predict if each pixel is cat, dog, or background.\n",
        "  You have 80% background pixels, 10% dog, and 10% cat. If the model predicts 100% background\n",
        "  should it be be 80% right (as with categorical cross entropy) or 30% (with this loss)?\n",
        "  The loss has been modified to have a smooth gradient as it converges on zero.\n",
        "  This has been shifted so it converges on 0 and is smoothed to avoid exploding\n",
        "  or disappearing gradient.\n",
        "  Jaccard = (|X & Y|)/ (|X|+ |Y| - |X & Y|)\n",
        "          = sum(|A*B|)/(sum(|A|)+sum(|B|)-sum(|A*B|))\n",
        "  \"\"\"\n",
        "  intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n",
        "  sum_ = K.sum(K.abs(y_true) + K.abs(y_pred), axis=-1)\n",
        "  jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
        "  return (1 - jac) * smooth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v9i_3V9NvGjR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss_factor = 10000\n",
        "def dice_coef(y_true, y_pred):\n",
        "  smooth = 1\n",
        "  y_true_f = K.flatten(y_true)\n",
        "  y_pred_f = K.flatten(y_pred)\n",
        "  intersection = K.sum(y_true_f * y_pred_f)\n",
        "  return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "  return -dice_coef(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mZOYfSHrwPeO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_loss_metrics_weights(out_resized_levels, use_dice=True, classify=False,\n",
        "                             segmentation_classes=1, only_labels=False,\n",
        "                             single_class=False, loss_factor=1.):\n",
        "  \n",
        "  loss_type = dice_coef_loss if use_dice else jaccard_distance\n",
        "  loss, metrics, loss_weights = dict(), dict(), dict()\n",
        "  \n",
        "  if classify:\n",
        "    if single_class:\n",
        "      loss['labels'] = 'categorical_crossentropy'\n",
        "      metrics['labels'] = 'categorical_accuracy'\n",
        "    else:\n",
        "      loss['labels'] = 'binary_crossentropy'\n",
        "      metrics['labels'] = 'binary_accuracy'\n",
        "    loss_weights['labels'] = loss_factor\n",
        "    \n",
        "    if only_labels:\n",
        "      return loss, metrics, loss_weights\n",
        "  \n",
        "  if segmentation_classes > 1:\n",
        "    l_p, m_p, lw_p = loss_type, [dice_coef, 'categorical_accuracy'], loss_factor\n",
        "    l_r, m_r, lw_r = 'categorical_crossentropy', ['categorical_accuracy'], loss_factor / (out_resized_levels + 1)\n",
        "  else:\n",
        "    l_p, m_p, lw_p = 'mse', ['acc'], loss_factor\n",
        "    l_r, m_r, lw_r = 'mse', ['acc'], loss_factor / (out_resized_levels + 1)\n",
        "    \n",
        "  loss['prediction'] = l_p\n",
        "  metrics['prediction'] = m_p\n",
        "  loss_weights['prediction'] = lw_p\n",
        "  \n",
        "  if out_resized_levels > 0:\n",
        "    for i in range(1, out_resized_levels + 1):\n",
        "      loss['resized_%d' % i] = l_r\n",
        "      metrics['resized_%d' % i] = m_r\n",
        "      loss_weights['resized_%d' % i] = lw_r\n",
        "    \n",
        "    \n",
        "  return loss, metrics, loss_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "34DVVqLsoZzB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_pre_resized(batch_imgs, steps):\n",
        "  pre_resized_imgs = {'or_image': batch_imgs}\n",
        "  or_size = batch_imgs.shape[1:-1]\n",
        "  for i in range(1, steps+1):\n",
        "    key = 'resized_image_%d' % i\n",
        "    size = or_size[0] // (2 ** i), or_size[1] // (2 ** i)\n",
        "    value = np.zeros((batch_imgs.shape[0], size[0], size[1], batch_imgs.shape[3]))\n",
        "    \n",
        "    for batch in range(batch_imgs.shape[0]):\n",
        "      value[batch] = cv2.resize(batch_imgs[batch], size)\n",
        "      \n",
        "    pre_resized_imgs[key] = value\n",
        "#   for key, value in pre_resized_imgs.items():\n",
        "#     print(key, value.shape)\n",
        "  return pre_resized_imgs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kSCSxd5E0WEL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Metrics(Callback):\n",
        "  # source: https://medium.com/@thongonary/how-to-compute-f1-score-for-each-epoch-in-keras-a1acd17715a2\n",
        "  def on_train_begin(self, logs={}):\n",
        "    self.val_f1s = []\n",
        "    self.val_recalls = []\n",
        "    self.val_precisions = []\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    val_predict = (np.asarray(self.model.predict(self.model.validation_data[0]))).round()\n",
        "    val_targ = self.model.validation_data[1]\n",
        "    _val_f1 = f1_score(val_targ, val_predict)\n",
        "    _val_recall = recall_score(val_targ, val_predict)\n",
        "    _val_precision = precision_score(val_targ, val_predict)\n",
        "    self.val_f1s.append(_val_f1)\n",
        "    self.val_recalls.append(_val_recall)\n",
        "    self.val_precisions.append(_val_precision)\n",
        "    print(\" — val_f1: %f — val_precision: %f — val_recall %f\" %(_val_f1, _val_precision, _val_recall))\n",
        "    return"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}