{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AtrusUnet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/dkatsios/semantic_segmentation/blob/master/AtrusUnet.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "L_mACA3lyT9V",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # https://pypi.python.org/pypi/pydot\n",
        "# !pip install pydot\n",
        "# !pip install graphviz\n",
        "# !apt-get install graphviz\n",
        "# import pydot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GaC6vrkTqojX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, Input, Concatenate, Deconv2D, Lambda, ZeroPadding2D\n",
        "from keras.models import Model\n",
        "\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "\n",
        "# from IPython.display import SVG\n",
        "# from keras.utils.vis_utils import model_to_dot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XP_C0trfq4qH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class AtrousUnet:\n",
        "  def __init__(self, img_shape, filters, out_channels,\n",
        "               steps, out_levels, kernel_sizes=None):\n",
        "    self.img_shape = img_shape\n",
        "    self.filters = filters\n",
        "    self.out_channels = out_channels\n",
        "    self.steps = steps\n",
        "    self.out_levels = out_levels\n",
        "    self.kernel_sizes = kernel_sizes if kernel_sizes is not None else [2, 3, 5, 7]\n",
        "    \n",
        "    assert 2 ** self.steps <= np.min(img_shape[:2]) and \\\n",
        "    self.out_levels <= self.steps\n",
        "    \n",
        "  def resize_img(self, input_tensor):\n",
        "    return tf.image.resize_images(input_tensor[0],\n",
        "                                  input_tensor[1].shape[1:-1])\n",
        "  \n",
        "  def check_shape(self, x):\n",
        "    x_shape = K.int_shape(x)[1:-1]\n",
        "    if x_shape == self.current_shape:\n",
        "      return x\n",
        "    \n",
        "    dr = self.current_shape[0] - x_shape[0]\n",
        "    if dr == 0:\n",
        "      r_pad = 0, 0\n",
        "    elif dr % 2 == 0:\n",
        "      r_pad = dr // 2, dr // 2\n",
        "    else:\n",
        "      r_pad = dr // 2, dr // 2 + 1\n",
        "    \n",
        "    dc = self.current_shape[1] - x_shape[1]\n",
        "    if dc == 0:\n",
        "      c_pad = 0, 0\n",
        "    elif dc % 2 == 0:\n",
        "      c_pad = dc // 2, dc // 2\n",
        "    else:\n",
        "      c_pad = dc // 2, dc // 2 + 1\n",
        "      \n",
        "    assert np.abs(np.array([r_pad, c_pad])).all() <= 1\n",
        "    if dr < 0 or dc < 0:\n",
        "      r = -r_pad[0], x_shape[0] + r_pad[1]\n",
        "      c = -c_pad[0], x_shape[1] + c_pad[1]\n",
        "      x = Lambda(lambda x: x[:,r[0]:r[1],c[0]:c[1],:])(x)\n",
        "    else:\n",
        "      x = ZeroPadding2D((r_pad, c_pad))(x)\n",
        "    return x\n",
        "  \n",
        "  def down_sampling_block(self, input_img, input_tensor, ind):\n",
        "    name = 'down_sampled_{}'.format(ind) if ind is not None else None\n",
        "\n",
        "    down_sampled = [Conv2D(self.filters, (2, 2), strides=(2, 2), padding='same',\n",
        "                         dilation_rate=(1, 1), activation='relu',\n",
        "                          name='x_{}'.format(ind))(input_tensor)]\n",
        "\n",
        "    for i, k in enumerate(self.kernel_sizes):\n",
        "      x = Conv2D(self.filters, (k, k), strides=(1, 1), activation='relu',\n",
        "                 padding='same', dilation_rate=(2, 2))(input_tensor)\n",
        "\n",
        "      x = Conv2D(self.filters, (2, 2), strides=(2, 2), activation='relu',\n",
        "                 padding='same')(x)\n",
        "      \n",
        "      down_sampled.append(x)\n",
        "\n",
        "    down_sampled = Concatenate()([*down_sampled])\n",
        "    resized_img = Lambda(self.resize_img)([input_img, down_sampled])\n",
        "    down_sampled = Conv2D(2 * self.filters - resized_img.get_shape().as_list()[-1],\n",
        "                          (1, 1), padding='same', name=name)(down_sampled)\n",
        "    down_sampled = Concatenate()([down_sampled, resized_img])\n",
        "\n",
        "    return down_sampled\n",
        "  \n",
        "  def up_sampling_block(self, down_1, down_0, ind=None):\n",
        "    up_name = 'up_sampled_{}'.format(ind) if ind is not None else None\n",
        "    out_name = 'out_sampled_{}'.format(ind) if ind is not None else None\n",
        "\n",
        "    up_sampled = Deconv2D(self.filters, (1, 1), activation='relu',\n",
        "                          strides=(2, 2), padding='same')(down_1)\n",
        "    \n",
        "    self.current_shape = K.int_shape(down_0)[1:-1]\n",
        "    up_sampled = self.check_shape(up_sampled)\n",
        "    \n",
        "    up_sampled = Concatenate()([up_sampled, down_0])\n",
        "    up_sampled = Conv2D(2 * self.filters, (1, 1), activation='relu',\n",
        "                        padding='same', name=up_name)(up_sampled)\n",
        "    out_sampled = Conv2D(self.out_channels+1, (1, 1), activation='softmax',\n",
        "                         padding='same', name=out_name)(up_sampled)\n",
        "    \n",
        "    return up_sampled, out_sampled\n",
        "  \n",
        "  def build_model(self):\n",
        "    input_img = Input(self.img_shape)\n",
        "    down_sampled = [input_img]\n",
        "\n",
        "    for i in range(self.steps):\n",
        "      down_sampled.append(self.down_sampling_block(input_img,\n",
        "                                                   down_sampled[i], i))\n",
        "\n",
        "    up_sampled = [down_sampled[-1]]\n",
        "    #############\n",
        "#     up_results = self.up_sampling_block(down_sampled[-1],\n",
        "#                                         down_sampled[-2], self.steps-1)\n",
        "#     up_sampled.append(up_results[1])\n",
        "    \n",
        "#     for i in range(3, self.steps+1):\n",
        "#       up_results = self.up_sampling_block(up_results[0],\n",
        "#                                      down_sampled[-i], self.steps-i)\n",
        "#       up_sampled.append(up_results[1])\n",
        "    #############\n",
        "    up_results = down_sampled[-1],\n",
        "    for i in range(2, self.steps+1):\n",
        "      up_results = self.up_sampling_block(up_results[0],\n",
        "                                          down_sampled[-i], self.steps-i)\n",
        "      \n",
        "      up_sampled.append(up_results[1])\n",
        "    ############\n",
        "      \n",
        "    up_results = self.up_sampling_block(up_results[0], input_img)\n",
        "    \n",
        "    up_sampled = up_sampled[-self.out_levels:]\n",
        "    if self.out_levels == 0:\n",
        "      up_sampled = []\n",
        "    \n",
        "    out_img = Conv2D(self.out_channels+1, (1, 1), activation='softmax',\n",
        "                        name='out_img')(up_results[0])\n",
        "    up_sampled.append(out_img)\n",
        "    model = Model(input_img, up_sampled)\n",
        "    \n",
        "    \n",
        "    assert self.img_shape[:-1] == model.layers[-1].output_shape[1:-1]\n",
        "    \n",
        "    self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hckMfqk5yPEW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  img_shape = 256, 256, 3\n",
        "  filters = 64\n",
        "  out_channels = 20\n",
        "  steps = 5\n",
        "  out_resized_levels = 2\n",
        "  kernel_sizes = [2, 3, 5]\n",
        "  atrous_unet = AtrousUnet(img_shape, filters, out_channels,\n",
        "                           steps, out_resized_levels, kernel_sizes)\n",
        "  atrous_unet.build_model()\n",
        "  losses = ['mse'] * (out_resized_levels + 1)  # binary_crossentropy\n",
        "  atrous_unet.model.compile(optimizer='Adam', loss=losses, metrics=['accuracy'])\n",
        "\n",
        "  print('number of parameters:', atrous_unet.model.count_params())\n",
        "  # print(atrous_unet.model.summary())\n",
        "  # SVG(model_to_dot(atrous_unet.model, show_shapes=True,\n",
        "  #                  show_layer_names=False).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}